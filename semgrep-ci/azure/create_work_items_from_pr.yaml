variables:
- group: Semgrep_Variables

steps:
- checkout: self
  clean: true
  fetchDepth: 100000
  persistCredentials: true
- script: |
    python -m pip install --upgrade pip
    pip install semgrep
    if [ $(Build.SourceBranchName) = "master" ]; then
        echo "Semgrep full scan"
        semgrep ci --json --output /home/vsts/work/1/a/findings.json
    elif [ $(System.PullRequest.PullRequestId) -ge 0 ]; then
        echo "Semgrep diff scan"
        export SEMGREP_PR_ID=$(System.PullRequest.PullRequestId)
        export SEMGREP_BASELINE_REF='origin/master'
        echo "Pull Request Scan from branch: $(Build.SourceBranchName)"
        echo "Pull Request Id: $(System.PullRequest.PullRequestId)"
        git fetch origin master:origin/master
        semgrep ci --json --output /home/vsts/work/1/a/findings.json
    fi

- task: Bash@3
  inputs:
    targetType: 'inline'
    script: |
      # this is inline code
      env | sort

##################################################################################################################
######## WORK ITEM CREATION ######################################################################################
##################################################################################################################
- task: PythonScript@0
  inputs:
    scriptSource: 'inline'
    script: |
      import requests
      import csv
      import os
      import pprint
      import json
      import logging
      import base64
      import urllib.parse
      from datetime import datetime

      # qq: import logging level from environment variable, default to INFO
      loglevel = os.getenv('LOG_LEVEL', 'INFO')
      semgrep_org = os.getenv('SEMGREP_ORG', 'xxxxx')
      logging.basicConfig(level=loglevel)
      logging.debug (loglevel)


      class WorkItem():
          '''Creating an Instance of Work Item'''

          def __init__(self):
              # Get the environment variables from the pipeline
              self.PROJECT_NAME = os.getenv('BUILD_REPOSITORY_NAME')
              self.SYSTEM_COLLECTIONURI = os.getenv('SYSTEM_COLLECTIONURI')
              self.SYSTEM_TEAMPROJECT = os.getenv('SYSTEM_TEAMPROJECT')
              self.SYSTEM_TEAMPROJECTID = os.getenv('SYSTEM_TEAMPROJECTID')
              self.BUILD_REPOSITORY_ID = os.getenv('BUILD_REPOSITORY_ID')
              self.BUILD_REPOSITORY_URI = os.getenv('BUILD_REPOSITORY_URI')
              self.BUILD_REPOSITORY_NAME = os.getenv('BUILD_REPOSITORY_NAME')
              self.BUILD_REQUESTEDFOREMAIL=os.getenv('BUILD_REQUESTEDFOREMAIL') 
              self.PIPELINESTARTTIME = os.getenv('SYSTEM_PIPELINESTARTTIME')
              self.PULLREQUESTID = 0
              temp = os.getenv('SYSTEM_PULLREQUEST_SOURCEBRANCH')
              self.BUILD_SOURCEBRANCHNAME = temp[temp.rindex('refs/heads')+11:]

              # create the URL for Work Items
              self.url_to_work_items = f"{self.SYSTEM_COLLECTIONURI}{self.SYSTEM_TEAMPROJECTID}/_apis/wit/workitems/%24task"
              self.url_link_to_repo = f"{self.BUILD_REPOSITORY_URI}"
              self.headers_work_items = {
                  "Content-Type": "application/json-patch+json"
              }

          def find_pr_id(self): 
              # find the Pull Request ID
              self.PULLREQUESTID = $(System.PullRequest.PullRequestId)
              logging.debug (f"Pull Request ID is {self.PULLREQUESTID}")

          def get_deployment(self) -> str:
              token_api = os.getenv('SEMGREP_APP_TOKEN')  
              headers = {"Accept": "application/json", "Authorization": "Bearer " + token_api}

              r = requests.get('https://semgrep.dev/api/v1/deployments',headers=headers)
              if r.status_code != 200:
                  logging.error(f"Sending message failed with comment: {r.text}")
              data = json.loads(r.text)
              slug_name = data['deployments'][0].get('slug')
              logging.debug(f"Accessing org: {slug_name}")
              return slug_name
          
          def get_findings_per_repo(self, slug_name: str, repo: str, file_path: str):      
              logging.debug (f"Getting findings!")
              token_api = os.getenv('SEMGREP_APP_TOKEN')  
              headers = {"Accept": "application/json", "Authorization": "Bearer " + token_api}
              r = requests.get('https://semgrep.dev/api/v1/deployments/' + slug_name + '/findings?dedup=true&repos='+repo,headers=headers)
              if r.status_code != 200:
                logging.error(f"Sending message failed with comment: {r.text}")
              data = json.loads(r.text)
              logging.debug (f"Dumping findings to: {file_path}")
              with open(file_path, "w") as file:
                json.dump(data, file)


          def add_work_items(self, title: str, summary: str, file_info: str, vuln_code_url: str, severity:str, url_to_semgrep: str, area: str, tags: str) -> bool:
              ''' Add work items to Azure DevOps Pull Request'''
              logging.info (f"Added workitem")
              link_to_pr = '{ "op": "add", "path": "/relations/-", "value": { "rel": "ArtifactLink", "url": "vstfs:///Git/PullRequestId/'+ str(self.SYSTEM_TEAMPROJECTID) +'/'+ str(self.BUILD_REPOSITORY_ID) +'/'+ str(self.PULLREQUESTID) +'", "attributes": { "name": "pull request" } } }'
              html_description = "<!DOCTYPE html> <html> <body> <p> <strong>Summary: </strong>" + summary + "</p> <p></p> <p><strong>Link to code: </strong><a href=" + vuln_code_url + ">" + file_info + "</a></p><p></p><p><strong>Link to project findings in Semgrep: </strong><a href=" + url_to_semgrep + ">" + url_to_semgrep + "</a></p><p></p><p><strong>Severity: </strong>" + severity + "</p></body></html> "
              data = '[ { "op": "add", "path": "/fields/System.Title", "from": null, "value": "' + title + '" }, { "op": "add", "path": "/fields/System.AssignedTo", "value": "'+ self.BUILD_REQUESTEDFOREMAIL + '" },' + link_to_pr + ', { "op": "add", "path": "/fields/System.Tags", "value":  "'+ tags + '" },{ "op": "add", "path": "/fields/System.AreaPath", "value":  "'+ area + '" }, { "op": "add", "path": "/fields/System.Description", "value": "' + html_description + '" }]'
              logging.debug(f"{data}")
              params = {
                  'api-version': '7.0',
              }
              pat=os.getenv('SYSTEM_ACCESSTOKEN')
              r = requests.post(url=self.url_to_work_items,
                                headers=self.headers_work_items, 
                                params=params,
                                data=data, 
                                auth=('', pat),
                              )

              if r.status_code == 200:
                  logging.info (f"Added workitem successfully")
                  return True
                  
              else:
                  logging.error (f"Error in adding workitem, status_code : {r.status_code}")
                  logging.error (f"Error in adding workitem, headers : {r.headers}")
                  logging.error (f"Error in adding workitem, text : {r.text}")
                  return False

          def read_csv_file(self, file_path: str):
              # Your Azure DevOps details
              organization = os.getenv('CONTRIBUTOR_ORGANIZATION')
              project = os.getenv('CONTRIBUTOR_PROJECT')
              repository = os.getenv('CONTRIBUTOR_REPOSITORY')
              path_to_file = os.getenv('CONTRIBUTOR_PATH_TO_FILE')
              pat=os.getenv('SYSTEM_ACCESSTOKEN')
              # Construct the URL
              url = f"https://dev.azure.com/{organization}/{project}/_apis/git/repositories/{repository}/items?path={path_to_file}&api-version=6.0&download=true"

              # Make the request
              response = requests.get(url, headers={'Authorization': f'Basic {pat}'})

              # Ensure the request succeeded
              if response.status_code == 200:
                  csv_file = response.content
                  with open(file_path, 'wb') as file:
                      file.write(response.content)
                  logging.debug(csv_file)
              else:
                  logging.error(f"Failed to retrieve file: {response.status_code}")

          def get_area_path(self, file_path: str, email: str, default_value: str):
              with open(file_path, mode='r', encoding='utf-8') as csvfile:
                  reader = csv.DictReader(csvfile)
                  for row in reader:
                      if row['email_contributor'] == email:
                          return row['area_path']
              logging.error(f"No area_path found for this email: {email}")
              return default_value

      workitem = WorkItem()
      workitem.find_pr_id()
      # Getting findings
      try:
          path = '/home/vsts/work/1/a/findings_api.json'
          project_name = workitem.PROJECT_NAME
          org_name = workitem.get_deployment()
          branch_name = workitem.BUILD_SOURCEBRANCHNAME
          workitem.get_findings_per_repo(org_name, project_name, path)
          f = open(path)
          findings = json.load(f)
      except FileNotFoundError:
          logging.error("File findings.json not found at /home/vsts/work/1/a/findings_api.json")
      except Exception as e:
          logging.error(f"Unknown error: {e}")
      finally:
          f.close()
     
      # Getting the CSV match list with AreaPath and email contributor.
      workitem.read_csv_file("temp.csv")
      default_area = "WebGoat\\\Review"
      email_to_search = workitem.BUILD_REQUESTEDFOREMAIL
      logging.info(f"Email to search: {email_to_search}")
      work_item_area = workitem.get_area_path("temp.csv", email_to_search, default_area)
      logging.info(f"work_item_area: {work_item_area}")

      # Iterating through the findings in findings.json file
      for i in findings['findings']:
          logging.debug (f"finding is {i}")

          work_item_finding_id = i['id']
          logging.debug (f"work_item_finding_id is {work_item_finding_id}")

          work_item_summary = i['rule_name']
          logging.debug (f"work_item_summary is {work_item_summary}")

          work_item_message = i['rule_message']
          logging.debug (f"work_item_message is {work_item_message}") 

          work_item_severity = i['severity']
          logging.debug (f"work_item_severity is {work_item_severity}") 
          
          work_item_relevant_since = i['relevant_since']
          logging.debug (f"work_item_relevant_since is {work_item_relevant_since}") 

          work_item_policy = i['sourcing_policy']['slug']
          logging.debug (f"work_item_policy is {work_item_policy}") 

          work_item_file_info = i['location']['file_path'] + ":" + str(i['location']['line'])
          logging.debug (f"work_item_file_info is {work_item_file_info}") 

          work_item_vuln_code_url = f"{workitem.url_link_to_repo }" \
                              f"?path=/{i['location']['file_path']}&" \
                              f"version=GB{workitem.BUILD_SOURCEBRANCHNAME}&" \
                              f"line={i['location']['line']}&" \
                              f"lineEnd={i['location']['end_line']}&" \
                              f"lineStartColumn={i['location']['column']}&" \
                              f"lineEndColumn={i['location']['end_column']}&" \
                              f"lineStyle=plain&_a=contents"

          ## format: 2023-09-18 07:49:42+00:00
          time_pipeline = workitem.PIPELINESTARTTIME[0:19]
          time_pipeline = datetime.strptime(time_pipeline, '%Y-%m-%d %H:%M:%S')
          logging.debug(time_pipeline)
          
          ## 2023-09-15T15:34:38.059101Z
          work_item_relevant_since = work_item_relevant_since[0:19]
          time_relevante_since = datetime.strptime(work_item_relevant_since, '%Y-%m-%dT%H:%M:%S')
          logging.debug(time_relevante_since)

          url_to_semgrep = f"https://semgrep.dev/orgs/{org_name}/findings?repo={project_name}&ref={branch_name}"

          if (time_relevante_since > time_pipeline and work_item_policy != 'rule-board-audit'):
              logging.info(f"New finding: {work_item_finding_id}")
              workitem.add_work_items(work_item_summary, work_item_message, work_item_file_info, work_item_vuln_code_url, work_item_severity, url_to_semgrep, work_item_area, "semgrep")
        
      # Closing file
      f.close()                    
  env:
    SYSTEM_ACCESSTOKEN: $(System.AccessToken)
    LOG_LEVEL: DEBUG
  condition: ne(variables['Build.SourceBranchName'], 'master')
    
  displayName: 'Python script to add work items'
